\chapter{Implementation}
\label{chap:implementation}
In this chapter, the implementation of the network stack using the
pipelined design from chapter \ref{chap:design} is outlined and described,
the application of SME detailed and evaluated, and lastly, the viability
of the system on an FPGA is discussed.\\
The network stack is implemented in C\# using the C\# version of SME, which is,
at the moment of writing, more mature and feature-rich. The current version of
the implementation supports most of the absolutely vital parts of the IPv4
protocol, as well as the UDP protocol, as specified by RFC 1122\cite{RFC1122}.
Although work has been carried out in order to ensure that additional protocols
can be implemented without obstructions, no additional protocols are supported
at the moment.\\
The solution is fairly well-divided into 3 different types of components,
relating closely to those of SME: processes, buffers, and busses. The most
interesting parts of these components will be described in further detail in the
following sections.


\section{Processes}
The processes are arguably the most vital part of the system, as they provide
the computation and "processing" on the in- and out-going packets.
It is important to note that although there are many other types of "processes",
in the network, such as the buffers, we will mainly refer to the modules doing
actual business-logic as "processes" \footnote{These processes are not to be
confused with SME processes, which are used for the implementation of both the
buffers and processes.}.

The essential processes in the network are represented as light-grey boxes in
the figure \ref{fig:final_design}. These processes are \texttt{Internet\_In},
\texttt{Internet\_Out}, and \texttt{Transport}.


\subsection{State-machines}
Network communication can consists of countless different packets, formats,
protocols, combinations of flags and settings, and even errors and corrupted
bits. The processes in the network have to take on a manifold of jobs in order
to handle all these scenarios, which sadly cannot be handled with a simple
combinational logic circuit. To operate under these various conditions, these
processes are modelled as finite state machines, maintaining a single state at
all times.\\
The processes have a lot of similar states, such as \texttt{Idle}, \texttt{Receive},
\texttt{Pass}, or \texttt{Send}, but these can work very differently, as shown
in the following sections. Before moving on to describing the state-machines of
the 3 processes, it is crucial to understand how these can be modelled in SME.

\subsubsection{SME process execution flow}
To implement a process in SME, the C\# class has to inherit from
either the \texttt{Process} abstract class, or the more simple
\texttt{SimpleProcess} class.
The latter class is, as its name states, a simpler version of the former. This
class implements an \texttt{OnTick()} method, which is invoked once for every
clock-cycle.\\
The more advanced, but also more capable \texttt{Process} class provides
an abstract method \texttt{Run} which is to be overriden and filled
with the code desired to be run in the process. The interesting feature
about this method is that it is asynchronous, meaning that the code can
execute other tasks while waiting for resources, such as functions,
to return. In this case, this asynchronous feature is used to give
the programmer ability to split the function into multiple segments,
separated by the clock signal.\\
Figure \ref{fig:example_fsm} compares these two approaches for the same
finite state-machine with 3 consequtive states.

The "synchronous" approach using a \texttt{SimpleProcess} in subfigure
\ref{fig:sme_example_process_sync_code} has to implement a
variable tracking the current state of the process. On each new clock, this
state has to be analysed and the inteded function to be called based on the
value. This approach requires a lot of approach and boilerplate code, especialy
if there are several states.\\
The asynchronous approach on subfigure
\ref{sme_example_process_async_code} on the other hand can do with only
single \texttt{Run()} method split into three parts -- A, B, and C.
After each code-segment, the process waits for the clock signal, and
continues with the execution of the next segment.  This functionality
gives the programmer a very granular control of the way a process
works, how it is split into multiple steps on the hardware, while
maintaining simplicity, as seen on the statemachine diagram on subfigure
\ref{fig:sme_example_process_fsm}.

\begin{figure*}
    \begin{subfigure}[b]{0.3\textwidth}
        \centering
\begin{lstlisting}[language={[Sharp]C}]
public class SomeProcess : StateProcess
{
  private override async Task OnTickAsync()
  {
    // A
    await ClockAsync();
    // B
    await ClockAsync();
    // C
    await ClockAsync();
  }
}
\end{lstlisting}
        \caption{Example using inheriting from \texttt{Process}, using the \texttt{Run()} asynchronous method.}
	\label{fig:sme_example_process_async_code}
    \end{subfigure}
\hfill
    \begin{subfigure}[b]{0.3\textwidth}
\begin{lstlisting}[language={[Sharp]C}]
public class SomeProcess : SimpleProcess
{
// Initial state
state = A;

protected override void OnTick()
{
  switch(state) {
    case A:
      a();
      state = B;
    case B:
      b();
      state = C;
    case C:
      c();
      state = A;
  }

}
\end{lstlisting}
	\caption{Example pseudocode of using a "synchronous" \texttt{SimpleProcess}}
	\label{fig:sme_example_process_sync_code}
    \end{subfigure}
\hfill
 \begin{subfigure}[b]{0.3\textwidth}
        \centering
        \includegraphics[scale=0.45]{implementation/empty_process_fsm.eps}
        \caption{The statemachine resulting from both code-examples}
 	\label{fig:sme_example_process_fsm}
\end{subfigure}
    \caption{A simple state-machine implemented in the asynchronous (left) and
asynchronous (right) approach in SME using C\#}
    \label{fig:example_fsm}
\end{figure*}


\subsubsection{\texttt{Internet Out} state machine}
This way of modelling a process in SME first the \texttt{Internet Out} process
very well, as it only has one responsibility, which is reading outgoing segments
and wrapping them in an Internet header. The figure \ref{fig:internet_out_implementation} shows the pseudo-code and state-machine for the \texttt{Internet Out}
process. This process was easy to model and implement, because it only has one
input and one output, and the state-changes are simple and intuitive.

\begin{figure*}[htpb]
    \centering
    \begin{subfigure}[b]{0.5\textwidth}
        \centering
\begin{lstlisting}[language={[Sharp]C}]
public partial class InternetOut: StateProcess
{
public override async Task OnTickAsync()
{
  while segment_available() {
    pass_segment();
    await ClockAsync();
  }

  while header_available() {
    pass_header();
    await ClockAsync();
  }
}
}
\end{lstlisting}
        \caption{Pseudo-code for the \texttt{InternetOut} process}
	\label{fig:internet_out_pseudocode}
    \end{subfigure}%
    \begin{subfigure}[b]{0.50\textwidth}
        \centering
        \includegraphics[scale=0.45]{implementation/internet_out_fsm.eps}
        \caption{The statemachine for the \texttt{InternetOut} process}
 	\label{fig:internet_out_fsm}
    \end{subfigure}%
    \caption{The implementation of the \texttt{InternetOut} process}
    \label{fig:internet_out_implementation}
\end{figure*}


\subsubsection{\texttt{Internet In} and \texttt{Transport} state machines}
Unfortunately,
The state-machine of \texttt{Internet In} is probably the most simple of all the
state-machines, as it can effectively only read new packets from the Link-layer,
and pass it along the pipeline. Although it might be desireable for the Internet
layer to send control packets out to the network, this is not supported in the
current build.



\begin{figure*}[t]
    \centering
    \begin{subfigure}[t]{0.5\textwidth}
        \centering
        \includegraphics[scale=0.45]{implementation/internet_in_fsm.eps}
        \caption{The \texttt{Internet In} state machine}
    \end{subfigure}%
    \begin{subfigure}[t]{0.5\textwidth}
        \centering
        \includegraphics[scale=0.45]{implementation/transport_fsm.eps}
        \caption{The \texttt{Transport} state machine}
    \end{subfigure}%

    \caption{Statemachines for \texttt{Internet In} and \texttt{Transport}}
\end{figure*}

\subsubsection{\texttt{Internet Out} state machine}


\subsection{Internal memory}


\section{Buffers}
\subsection{Internal memory}
\subsection{IPv4 de-fragmentation and segment unification}
\subsection{Allocation}


\section{Busses}
\section{Interface Signal protocols}
\label{sec:interface_signal_protocol}
With the introduction of buffers between each parsing processes, a clear pattern
emerged. The layer-handling processes are responsible for numerous real-time tasks
(parsing, sending, protocol-specific tasks, etc), while also limited by their
fixed internal buffers. These processes are not always ready to receive input
from preceding processes, while they at the same time must be able to write their
output to following processes immediately.\\
The buffers are a stark opposite, as their large internal block memories enable
them to buffer huge chunks of memory, while also being able to wait for the
succeeding process to start reading.\\
With these two established scenarios, protocols for each can be proposed -- the
Buffer-Producer protocol, and the Compute-Producer protocol.

\subsection{Buffer-Producer}
The Buffer-Producer (BP) is the interface signal protocol where the producer of
the data is a buffer process (such as \texttt{Data Out} or \texttt{Segment
Out}).\\
The Buffer-Producer is heavily inspired by the Transfer signalling protocol in
the AXI4-Stream standard, which ensures a two-way flow-control mechanism for both
the producer and the consumer\footnote{The producer and consumer are called
master and slave respectively in the AXI4 specification.}\cite{arm_axi4}.

\begin{figure}[h]
\centering
\includegraphics[scale=0.8]{implementation/axi4_handshake.eps}
\caption{The AXI4 handshake process, adapted from “AMBA 4 AXI4 Stream-Protocol
specification” by ARM, 2010, p. 19.}
\label{fig:axi4_handshake}
\end{figure}

The AXI4 protocol uses two signals (also called "flags"), the \texttt{TVALID}
on master, and \texttt{TREADY} on slave. Every time both \texttt{TVALID} and
\texttt{TREADY} are asserted during a clock-cycle, a data-exchange happens.
Figure \ref{fig:axi4_handshake} shows a data exchange, where the information
(the bytes) are placed on the bus and the \texttt{TVALID} is raised. When this
signal propagates to the slave, it asserts \texttt{TREADY}. When this signal
propagates back to the master, it knows that the information was read, and that
it can proceed with the next byte, or in this case, de-assert the
\texttt{TVALID} to indicate no more bytes available\cite{arm_axi4}.

The information transferred in the AXI4 protocol can be defined by the user,
but it usually is a payload consisting of multiple element, such as a byte
location or the type of the data.\\

The Buffer-Producer protocol draws heavy inspiration from this model, as it
provides a simple flow-protocol with only a few flags. In the BP protocol,
the producer has a \texttt{valid} flag, while the consumer has the
\texttt{ready} flag. However, without any modifications, the AXI4 protocol sees
the data exchanged as being a single data-stream.
In the case of the Buffer-Producer however, we want to differentiate between the
end of a packet (or simply just a segment of data), and the beginning of a new
one. In the very first iterations, this was done by distinguishing the parsed
data by finding a known delimiter, such as the ID of the IPv4 packet, or the
sequence number of the TCP header. Unfortunately, this solution is very
dependent on the scenario where different delimiters might appear, or not be
present at all. To generalize this issue, an additional signal
\texttt{bytes\_left} is added to the control bus of the protocol, which
indicates the end of a current data-block by setting \texttt{bytes\_left = 0}.
The final Buffer-Producer protocol can be summed up in these following rules:
\begin{itemize}
	\item A data transfer only occurs if both \texttt{valid} and \texttt{ready}
		are raised at the same clock-cycle.
	\item When the producer has data available, it is immediately put in
		the bus and the \texttt{valid} flag is raised.
	\item Once the \texttt{valid} flag is raised, it cannot be reset until
		a data-transfer occurs.
	\item The consumer is allowed to wait until the \texttt{valid} flag is
		raised before raising the \texttt{ready} flag.
	\item If a consumer raises the \texttt{ready} flag, it is allowed to
		reset it before \texttt{valid} is raised.
\end{itemize}

The conventional data-exchange using the BP protocol in the network
stack is perhaps better visualized by a sequence diagram on figure
\ref{fig:buffer_producer}.


\begin{figure}
	\centering
	\includegraphics[scale=0.5]{implementation/buffer_producer.eps}
	\caption{The usual data-transfer between a buffer (Producer) and a
	compute-process (Consumer).}
	\label{fig:buffer_producer}
\end{figure}



\subsection{Compute-Producer}
The Compute-Producer (CP) protocol is the interface signal protocol from a
compute-process to a buffer. The requirement for this protocol is that
compute-processes do not usually have the luxury of being able to wait with the
data transfer, which usually happens if the compute-process is building a
packet header or passing information along from another buffer.

The concept for the Compute-Producer model is fairly simple; since the producer
(compute-process) does not have the luxury to wait, it always sends the data
on the bus, regardless if the consumer is ready. It is up to the producer to
mark the end of an ongoing data-stream.\\

Thus, the rules for the Compute-Producer protocol are as such:
\begin{itemize}
	\item If the producer puts data on the bus, the \texttt{valid} flag
		must be raised.
	\item If \texttt{bytes\_left} is greater than $0$, the data in the next
		clock will be valid.
	\item If \texttt{bytes\_left} is $0$, the current byte ends the
		current sequence of bytes.
	\item If the consumer deasserts \texttt{ready}, it \textit{may} not read the
		data in the bus.
	\item The producer may act upon the knowledge that the consumer is
		either reading (\texttt{ready = true}) or ignoring
		(\texttt{ready = false}) the data.
\end{itemize}

Such a scenario is visualized on figure \ref{fig:compute_producer}, where the
consumer becomes unavailable during the transaction. The producer has the
opportunity to drop the transaction, but it might also continue till the end.

\begin{figure}
	\centering
	\includegraphics[scale=0.5]{implementation/compute_producer.eps}
	\caption{The usual data-transfer between a compute-process (Producer) and a
	buffer (Consumer). Note that the consumer becomes unavailable halfway through the
	transaction.}
	\label{fig:compute_producer}
\end{figure}



\section{Interface Control}
\subsection{Usage}
\subsection{Limitations}

